{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fc166a",
   "metadata": {},
   "source": [
    "# <h1 style=\"text-align: center; font-weight: bolder;\">FINAL PROJECT </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e432c18",
   "metadata": {},
   "source": [
    "<h4>DATA PREP & SETUP</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import soundfile as sf\n",
    "from scipy.signal import resample_poly, stft, istft\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "# para que los gráficos se vean bien en Jupyter y en Colab\n",
    "%matplotlib inline\n",
    "\n",
    "# base dir for sounds\n",
    "BASE_DIR = \"sounds\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# Freesound API\n",
    "API_KEY = \"RyxVkKLbV8VUlkfb4QShilfmPTgevqv6BfEBEhTV\"  \n",
    "# universildo/sounds/415627\n",
    "SOUND_ID = 415627                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b87a5",
   "metadata": {},
   "source": [
    "<h2><b>PART 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327ae58",
   "metadata": {},
   "source": [
    "## SOUND DOWNLOAD AND EDITION\n",
    "\n",
    "\n",
    "In the setup we also put a try catch/except for whenever freesound is down, as it happen during the development of this final project.\n",
    "\n",
    "If that's the case, you'll be asked to upload the audio. \n",
    "\n",
    "**URL for audio saved in private cloud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d068e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping de descriptores (ej 9)\n",
    "descriptorMapping = {\n",
    "    0: 'lowlevel.spectral_centroid.mean',\n",
    "    1: 'lowlevel.dissonance.mean',\n",
    "    2: 'lowlevel.hfc.mean',\n",
    "    3: 'sfx.logattacktime.mean',\n",
    "    4: 'sfx.inharmonicity.mean',\n",
    "    5: 'lowlevel.spectral_contrast.mean.0',\n",
    "    6: 'lowlevel.spectral_contrast.mean.1',\n",
    "    7: 'lowlevel.spectral_contrast.mean.2',\n",
    "    8: 'lowlevel.spectral_contrast.mean.3',\n",
    "    9: 'lowlevel.spectral_contrast.mean.4',\n",
    "    10: 'lowlevel.spectral_contrast.mean.5',\n",
    "    11: 'lowlevel.mfcc.mean.0',\n",
    "    12: 'lowlevel.mfcc.mean.1',\n",
    "    13: 'lowlevel.mfcc.mean.2',\n",
    "    14: 'lowlevel.mfcc.mean.3',\n",
    "    15: 'lowlevel.mfcc.mean.4',\n",
    "    16: 'lowlevel.mfcc.mean.5'\n",
    "}\n",
    "\n",
    "# convierte dict de features a vector (eje 9)\n",
    "def convFtrDict2List(ftrDict):\n",
    "    ftr = []\n",
    "    for key in range(len(descriptorMapping.keys())):\n",
    "        try:\n",
    "            ftrName, ind = '.'.join(descriptorMapping[key].split('.')[:-1]), int(descriptorMapping[key].split('.')[-1])\n",
    "            ftr.append(ftrDict[ftrName][0][ind])\n",
    "        except:\n",
    "            ftr.append(ftrDict[descriptorMapping[key]][0])\n",
    "    return np.array(ftr)\n",
    "\n",
    "# convierte analysis_json de freesound al formato que convFtrDict2List necesita\n",
    "def convAnalysisJson2Flat(analysis_json, descriptorMapping):\n",
    "    ftrDict = {}\n",
    "    for idx, desc_name in descriptorMapping.items():\n",
    "        parts = desc_name.split('.')            # ['lowlevel','mfcc','mean','0'] etc\n",
    "        group = parts[0]                        # lowlevel o sfx\n",
    "        feat = parts[1]                         # mfcc, spectral_centroid, etc\n",
    "        stat = parts[2]                         # mean\n",
    "        \n",
    "        val = None\n",
    "        try:\n",
    "            node = analysis_json[group][feat]   # subnodo relevante\n",
    "            \n",
    "            # caso escalar: lowlevel.hfc.mean, sfx.logattacktime.mean, etc\n",
    "            if len(parts) == 3:\n",
    "                val = node[stat]\n",
    "            \n",
    "            # caso vector: lowlevel.mfcc.mean.3, spectral_contrast.mean.4, etc\n",
    "            elif len(parts) == 4:\n",
    "                i = int(parts[3])\n",
    "                val = node[stat][i]\n",
    "        \n",
    "        except:\n",
    "            val = None\n",
    "        \n",
    "        # fallback si no hay valor\n",
    "        if val is None:\n",
    "            ftrDict[desc_name] = [0.0]\n",
    "        else:\n",
    "            ftrDict[desc_name] = [float(val)]\n",
    "    \n",
    "    return ftrDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convAnalysisJson2Flat(analysis_json, descriptorMapping):\n",
    "    \"\"\"\n",
    "    Convierte el JSON de analysis de Freesound (estructura anidada)\n",
    "    a un diccionario 'flattened' compatible con convFtrDict2List.\n",
    "\n",
    "    Claves del flat dict = strings en descriptorMapping (e.g. 'lowlevel.mfcc.mean.0')\n",
    "    Valores = [valor_descriptor]\n",
    "    \"\"\"\n",
    "    ftrDict = {}\n",
    "\n",
    "    for idx, desc_name in descriptorMapping.items():\n",
    "        parts = desc_name.split('.')  # p.ej. ['lowlevel','mfcc','mean','0'] o ['lowlevel','spectral_centroid','mean']\n",
    "        \n",
    "        group = parts[0]   # 'lowlevel' o 'sfx'\n",
    "        feat  = parts[1]   # 'mfcc', 'spectral_centroid', 'spectral_contrast', 'logattacktime', 'inharmonicity', ...\n",
    "        stat  = parts[2]   # normalmente 'mean'\n",
    "\n",
    "        val = None\n",
    "        try:\n",
    "            node = analysis_json[group][feat]\n",
    "\n",
    "            # caso escalar: lowlevel.spectral_centroid.mean, lowlevel.hfc.mean, sfx.logattacktime.mean, etc.\n",
    "            if len(parts) == 3:\n",
    "                # Freesound: analysis_json['lowlevel']['spectral_centroid']['mean'] -> escalar\n",
    "                val = node[stat]\n",
    "\n",
    "            # caso vector: lowlevel.mfcc.mean.0, lowlevel.spectral_contrast.mean.3, etc.\n",
    "            elif len(parts) == 4:\n",
    "                idx_coef = int(parts[3])\n",
    "                vec = node[stat]         # Freesound: list/array\n",
    "                val = vec[idx_coef]\n",
    "\n",
    "        except Exception:\n",
    "            val = None\n",
    "\n",
    "        # si no pudimos obtener el valor, ponemos 0.0 (o podrías usar np.nan si prefieres)\n",
    "        if val is None:\n",
    "            ftrDict[desc_name] = [0.0]\n",
    "        else:\n",
    "            ftrDict[desc_name] = [float(val)]\n",
    "\n",
    "    return ftrDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de168ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try/except para evitar crash si freesound esta down o la api falla\n",
    "use_freesound = True\n",
    "raw_path = None\n",
    "\n",
    "try:\n",
    "    # metadata url\n",
    "    meta_url = f\"https://freesound.org/apiv2/sounds/{SOUND_ID}/?token={API_KEY}\"\n",
    "    \n",
    "    # request metadata\n",
    "    meta_response = requests.get(meta_url, timeout=10)\n",
    "\n",
    "    if not meta_response.ok:\n",
    "        print(\"HTTP status:\", meta_response.status_code)\n",
    "        print(\"response text:\", meta_response.text)\n",
    "        raise RuntimeError(\"Error al pedir metadata de Freesound (API key / ID)\")\n",
    "    \n",
    "    meta = meta_response.json()\n",
    "\n",
    "    # preview-hq-ogg\n",
    "    preview_url = meta[\"previews\"][\"preview-hq-ogg\"]\n",
    "    print(\"Audio title:\", meta.get(\"name\", \"\"))\n",
    "    print(\"Duration in seconds:\", meta.get(\"duration\", \"N/A\"))\n",
    "    print(\"Preview URL:\", preview_url)\n",
    "\n",
    "    # preview download\n",
    "    raw_path = os.path.join(BASE_DIR, f\"universildo_{SOUND_ID}_preview.ogg\")\n",
    "    audio_response = requests.get(preview_url, timeout=10)\n",
    "    if not audio_response.ok:\n",
    "        print(\"Audio HTTP status:\", audio_response.status_code)\n",
    "        raise RuntimeError(\"No se pudo descargar el preview de Freesound\")\n",
    "\n",
    "    with open(raw_path, \"wb\") as f:\n",
    "        f.write(audio_response.content)\n",
    "\n",
    "    print(\"Descarga desde Freesound OK\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"===========================================\")\n",
    "    print(\"ACHTUNG! ADVERTÈNCIA! ALERTE!:\")\n",
    "    print(\"Freesound not available o error en API:\")\n",
    "    print(e)\n",
    "    print(\"===========================================\\n\")\n",
    "\n",
    "    # primero intentar encontrar el archivo localmente en la carpeta sounds\n",
    "    candidate_paths = []\n",
    "\n",
    "    # buscar cualquier archivo en sounds/ que contenga el SOUND_ID en el nombre\n",
    "    for fname in os.listdir(BASE_DIR):\n",
    "        if str(SOUND_ID) in fname and fname.lower().endswith(('.wav', '.ogg', '.mp3', '.flac', '.aiff')):\n",
    "            candidate_paths.append(os.path.join(BASE_DIR, fname))\n",
    "\n",
    "    if len(candidate_paths) > 0:\n",
    "        # usar el primero encontrado\n",
    "        raw_path = candidate_paths[0]\n",
    "        print(\"Found existing local file in sounds folder:\")\n",
    "        for p in candidate_paths:\n",
    "            print(\"  -\", p)\n",
    "        print(\"Using:\", raw_path)\n",
    "    else:\n",
    "        # si no se encontró nada en sounds, entonces pedimos al usuario\n",
    "\n",
    "        # detectar si estamos en colab\n",
    "        in_colab = False\n",
    "        try:\n",
    "            import google.colab\n",
    "            in_colab = True\n",
    "        except ImportError:\n",
    "            in_colab = False\n",
    "\n",
    "        if in_colab:\n",
    "            print(\"Sube un archivo de audio manualmente (Colab).\")\n",
    "            from google.colab import files\n",
    "            uploaded = files.upload()\n",
    "            filename = list(uploaded.keys())[0]\n",
    "            raw_path = filename\n",
    "            print(\"File uploaded:\", raw_path)\n",
    "\n",
    "        else:\n",
    "            # fallback: pedir ruta manual por consola (sin tkinter)\n",
    "            print(\"Could not use Freesound and no local file was found in sounds folder.\")\n",
    "            raw_path = input(\"Enter full local path to an audio file: \").strip()\n",
    "            if raw_path is None or raw_path == \"\":\n",
    "                raise RuntimeError(\"No compatible file was selected.\")\n",
    "            print(\"File selected:\", raw_path)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# read audio\n",
    "x_raw, fs_raw = sf.read(raw_path)\n",
    "print(\"fs_raw:\", fs_raw, \"shape:\", x_raw.shape)\n",
    "\n",
    "# convertir a mono\n",
    "if x_raw.ndim > 1:\n",
    "    x_mono = np.mean(x_raw, axis=1)\n",
    "else:\n",
    "    x_mono = x_raw\n",
    "\n",
    "# sample to 44.1\n",
    "fs_target = 44100\n",
    "if fs_raw != fs_target:\n",
    "    g = math.gcd(fs_raw, fs_target)\n",
    "    up = fs_target // g\n",
    "    down = fs_raw // g\n",
    "    x_resampled = resample_poly(x_mono, up, down)\n",
    "    fs_proc = fs_target\n",
    "else:\n",
    "    x_resampled = x_mono\n",
    "    fs_proc = fs_raw\n",
    "\n",
    "# OJO: PARA CUANDO TENGAMOS QUE AJSUTAR\n",
    "# audio trim:  \n",
    "start_sec = 9.0   \n",
    "# max duracion. no cuando termina\n",
    "# probamos con 4 para que al ponerle bpm de 120 no hay problemas de tempo  \n",
    "max_dur_sec = 4\n",
    "\n",
    "dur_total = len(x_resampled) / fs_proc\n",
    "print(\"Total duration in s:\", dur_total)\n",
    "\n",
    "# si el start_sec está fuera de rango, lo reajustamos\n",
    "if start_sec >= dur_total:\n",
    "    print(\"WARNING: start_sec is greater than or equal to total duration.\")\n",
    "    print(\"Resetting start_sec = 0.0\")\n",
    "    start_sec = 0.0\n",
    "\n",
    "start_sample = int(start_sec * fs_proc)\n",
    "end_sample = start_sample + int(max_dur_sec * fs_proc)\n",
    "end_sample = min(end_sample, len(x_resampled))\n",
    "\n",
    "x_edit = x_resampled[start_sample:end_sample]\n",
    "\n",
    "# si por cualquier motivo el recorte queda vacío, usar todo el audio\n",
    "if len(x_edit) == 0:\n",
    "    print(\"WARNING: trimmed segment is empty. Using full signal instead.\")\n",
    "    x_edit = x_resampled.copy()\n",
    "\n",
    "print(\"Duration for assignment in s:\", len(x_edit) / fs_proc)\n",
    "\n",
    "# normalization\n",
    "# deletable\n",
    "peak = np.max(np.abs(x_edit)) + 1e-9\n",
    "x_edit = x_edit / peak * 0.9\n",
    "\n",
    "# save in with following configuraciones> wav, mono, 44.1 khz, 16 bit\n",
    "edited_path = os.path.join(BASE_DIR, f\"universildo_{SOUND_ID}_edit.wav\")\n",
    "sf.write(edited_path, (x_edit * 32767).astype(np.int16), fs_proc)\n",
    "print(\"Saved in path:\", edited_path)\n",
    "\n",
    "\n",
    "print(\"Saved in path:\", edited_path)\n",
    "\n",
    "ipd.Audio(x_edit, rate=fs_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intentar obtener analysis json desde freesound (si está arriba)\n",
    "analysis_json = None\n",
    "\n",
    "try:\n",
    "    analysis_url = (\n",
    "        f\"https://freesound.org/apiv2/sounds/{SOUND_ID}/analysis/\"\n",
    "        f\"?token={API_KEY}&descriptors=lowlevel,sfx\"\n",
    "    )\n",
    "    resp = requests.get(analysis_url, timeout=10)\n",
    "\n",
    "    if not resp.ok:\n",
    "        raise RuntimeError(\"error al pedir analysis\")\n",
    "\n",
    "    analysis_json = resp.json()\n",
    "    print(\"analysis descargado desde freesound\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"warning: no se pudo obtener analysis desde freesound\")\n",
    "    print(e)\n",
    "    analysis_json = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si tenemos analysis, convertimos a vector de 17 descriptores\n",
    "ftr_vec = None\n",
    "if analysis_json is not None:\n",
    "    ftrDict = convAnalysisJson2Flat(analysis_json, descriptorMapping)\n",
    "    ftr_vec = convFtrDict2List(ftrDict)\n",
    "    print(\"feature vector shape:\", ftr_vec.shape)\n",
    "    print(\"feature vector:\", ftr_vec)\n",
    "else:\n",
    "    print(\"no feature vector disponible (freesound analysis down or audio doesnt have one)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f18915",
   "metadata": {},
   "source": [
    "## AUDIO ANALYSIS\n",
    "\n",
    "Analysis of waveform, STFT and descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, fs = sf.read(edited_path)\n",
    "\n",
    "# aseguramos tipo float32, pero SIN reescalar\n",
    "if x.dtype != np.float32:\n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "t = np.arange(len(x)) / fs\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(t, x)\n",
    "plt.xlabel(\"Time in s\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Waveform – universildo 415627 (edited)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "ipd.Audio(x, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fbfde9",
   "metadata": {},
   "source": [
    "## _STFT and magnitude spectrogram_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf71c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_fft = 2048\n",
    "hop = 512\n",
    "win = \"hann\"\n",
    "\n",
    "f, tt, Zxx = stft(\n",
    "    x,\n",
    "    fs=fs,\n",
    "    window=win,\n",
    "    nperseg=N_fft,\n",
    "    noverlap=N_fft-hop,\n",
    "    padded=False,\n",
    "    boundary=None\n",
    ")\n",
    "\n",
    "mag = np.abs(Zxx)\n",
    "\n",
    "# espectrograma completo\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.pcolormesh(tt, f, 20*np.log10(mag+1e-8), shading=\"gouraud\")\n",
    "plt.colorbar(label=\"magnitude dB\")\n",
    "plt.xlabel(\"time in s\")\n",
    "plt.ylabel(\"frequency hz\")\n",
    "plt.title(\"magnitude spectrogram (full range)\")\n",
    "plt.ylim(0, fs/2)\n",
    "plt.show()\n",
    "\n",
    "# espectrograma con zoom en frecuencias útiles\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.pcolormesh(tt, f, 20*np.log10(mag+1e-8), shading=\"gouraud\")\n",
    "plt.colorbar(label=\"magnitude dB\")\n",
    "plt.xlabel(\"time in s\")\n",
    "plt.ylabel(\"frequency hz\")\n",
    "plt.title(\"magnitude spectrogram (0–8 kHz)\")\n",
    "plt.ylim(0, 8000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13743280",
   "metadata": {},
   "source": [
    "## _Descriptors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RMS\n",
    "rms = np.sqrt(np.mean(x**2))\n",
    "\n",
    "# zero crossing rate (aprox)\n",
    "zero_crossings = np.where(np.diff(np.sign(x)))[0]\n",
    "zcr = len(zero_crossings) / len(x)\n",
    "\n",
    "# Espectro medio + spectral centroid\n",
    "X_mean = np.mean(mag, axis=1)  \n",
    "freqs = f\n",
    "spectral_centroid = np.sum(freqs * X_mean) / (np.sum(X_mean) + 1e-9)\n",
    "\n",
    "print(f\"Duration in s: {len(x)/fs:.3f}\")\n",
    "print(f\"RMS: {rms:.4f}\")\n",
    "print(f\"Zero Crossing Rate (aprox): {zcr:.4f}\")\n",
    "print(f\"Avg spectral centroid in hz: {spectral_centroid:.1f}\")\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(freqs, 20*np.log10(X_mean+1e-8))\n",
    "plt.xlabel(\"Freq in hz\")\n",
    "plt.ylabel(\"Med magnitude\")\n",
    "plt.title(\"Spectral centroid of sound\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134426f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom temporal de un pequeño fragmento\n",
    "seg_start = 1.0   # s\n",
    "seg_dur = 0.1     # 100 ms\n",
    "s0 = int(seg_start * fs_proc)\n",
    "s1 = min(len(x_edit), s0 + int(seg_dur * fs_proc))\n",
    "\n",
    "t_seg = np.arange(s0, s1) / fs_proc\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(t_seg, x_edit[s0:s1])\n",
    "plt.xlabel(\"time in s\")\n",
    "plt.ylabel(\"amplitude\")\n",
    "plt.title(\"time-domain zoom ({}–{} s)\".format(seg_start, seg_start+seg_dur))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# espectro de un frame del espectrograma\n",
    "frame_idx = 40  # elige un frame interesante\n",
    "mag_frame = mag[:, frame_idx]\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(f, 20*np.log10(mag_frame+1e-8))\n",
    "plt.xlabel(\"frequency hz\")\n",
    "plt.ylabel(\"magnitude dB\")\n",
    "plt.title(\"spectrum of one frame (index {})\".format(frame_idx))\n",
    "plt.xlim(0, 8000)  # zoom en armónicos\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0bda9a",
   "metadata": {},
   "source": [
    "<h2><b>PART 2</h2>\n",
    "<h3><b>OPTION B</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a6ab7",
   "metadata": {},
   "source": [
    "## _Base analysis_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stft_analysis(x, fs, N_fft=2048, hop=512, win=\"hann\"):\n",
    "    f, t, Z = stft(\n",
    "        x, fs=fs, window=win,\n",
    "        nperseg=N_fft,\n",
    "        noverlap=N_fft-hop,\n",
    "        padded=False,\n",
    "        boundary=None\n",
    "    )\n",
    "    return f, t, Z\n",
    "\n",
    "def stft_synthesis(Z, fs, N_fft=2048, hop=512, win=\"hann\"):\n",
    "    _, x_rec = istft(\n",
    "        Z, fs=fs, window=win,\n",
    "        nperseg=N_fft,\n",
    "        noverlap=N_fft-hop,\n",
    "        input_onesided=True\n",
    "    )\n",
    "    return x_rec\n",
    "\n",
    "# Analysis & sintesis without transformacion\n",
    "N_fft_base = 2048\n",
    "hop_base = 512\n",
    "\n",
    "f_base, t_base, Z_base = stft_analysis(x, fs, N_fft=N_fft_base, hop=hop_base)\n",
    "x_rec = stft_synthesis(Z_base, fs, N_fft=N_fft_base, hop=hop_base)\n",
    "\n",
    "# length adj\n",
    "min_len = min(len(x), len(x_rec))\n",
    "x_rec = x_rec[:min_len]\n",
    "x_ref = x[:min_len]\n",
    "\n",
    "# if hay reconstruction error\n",
    "err = np.sqrt(np.mean((x_ref - x_rec)**2))\n",
    "print(f\"RMSE entre original y reconstruido: {err:.6f}\")\n",
    "\n",
    "ipd.Audio(x_rec, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963dbfb5",
   "metadata": {},
   "source": [
    "## 2.2 Individual transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_pitch_resample(x, fs, semitones):\n",
    "    \"\"\"Pitch shift simple for resampling (changes pitch & duration).\"\"\"\n",
    "    factor = 2 ** (semitones / 12.0)\n",
    "    y = resample_poly(x, up=int(1000*factor), down=1000)\n",
    "    fs_new = int(fs * factor)\n",
    "    return y, fs_new\n",
    "\n",
    "def transform_lowpass_fft(x, fs, cutoff_hz):\n",
    "    \"\"\"Simple low pass filter in the freq domain\"\"\"\n",
    "    N = len(x)\n",
    "    X = np.fft.rfft(x)\n",
    "    freqs = np.fft.rfftfreq(N, d=1/fs)\n",
    "    \n",
    "    H = (freqs <= cutoff_hz).astype(float)\n",
    "    Y = X * H\n",
    "    y = np.fft.irfft(Y, n=N)\n",
    "    return y\n",
    "\n",
    "def transform_brighten_spectral_tilt(x, fs, tilt_db_per_khz=6.0):\n",
    "    \"\"\"Highlight high freq sounds aplying a tilt in the db spectrum\"\"\"\n",
    "    f, t, Z = stft_analysis(x, fs, N_fft=2048, hop=512)\n",
    "    mag = np.abs(Z)\n",
    "    phase = np.angle(Z)\n",
    "    \n",
    "    freqs = f / 1000.0  # kHz\n",
    "    tilt = tilt_db_per_khz * freqs\n",
    "    tilt_lin = 10 ** (tilt / 20.0)\n",
    "    \n",
    "    mag_tilted = mag * tilt_lin[:, np.newaxis]\n",
    "    Z_tilted = mag_tilted * np.exp(1j * phase)\n",
    "    \n",
    "    y = stft_synthesis(Z_tilted, fs, N_fft=2048, hop=512)\n",
    "    return y\n",
    "\n",
    "def transform_spectral_freeze(x, fs, freeze_time=0.5):\n",
    "    \"\"\"\n",
    "    spec freezing in a specific moment to keep it. A kind of static drone\n",
    "    \"\"\"\n",
    "    f, t, Z = stft_analysis(x, fs, N_fft=2048, hop=512)\n",
    "    mag = np.abs(Z)\n",
    "    phase = np.angle(Z)\n",
    "    \n",
    "    # Elige el frame más cercano a freeze_time\n",
    "    frame_idx = np.argmin(np.abs(t - freeze_time))\n",
    "    mag_freeze = mag[:, frame_idx][:, np.newaxis]\n",
    "    \n",
    "    # Usa fase progresiva para evitar clicks grandes\n",
    "    phase_freeze = np.unwrap(phase[:, frame_idx][:, np.newaxis], axis=0)\n",
    "    Z_freeze = mag_freeze * np.exp(1j * phase_freeze)\n",
    "    \n",
    "    y = stft_synthesis(Z_freeze, fs, N_fft=2048, hop=512)\n",
    "    return y\n",
    "\n",
    "def transform_granular_shuffle(x, fs, grain_ms=80):\n",
    "    \"\"\"\n",
    "    Cut in bits and randomly sort. A bit experimental\n",
    "    \n",
    "    \"\"\"\n",
    "    grain_len = int(fs * grain_ms / 1000.0)\n",
    "    num_grains = len(x) // grain_len\n",
    "    x_cut = x[:num_grains * grain_len].copy()\n",
    "    \n",
    "    grains = x_cut.reshape(num_grains, grain_len)\n",
    "    order = np.random.permutation(num_grains)\n",
    "    grains_shuffled = grains[order, :]\n",
    "    \n",
    "    y = grains_shuffled.reshape(-1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Versión robusta de granular shuffle\n",
    "def transform_granular_shuffle(x, fs, grain_ms=80):\n",
    "    \"\"\"\n",
    "    Cut in bits and randomly sort. A bit experimental\n",
    "    if sound is too short, returns original sound\n",
    "    \"\"\"\n",
    "    grain_len = max(1, int(fs * grain_ms / 1000.0))\n",
    "    num_grains = len(x) // grain_len\n",
    "\n",
    "    # if not enough, no hacemos nada aleatorio\n",
    "    if num_grains < 2:\n",
    "        return x.copy()\n",
    "\n",
    "    x_cut = x[:num_grains * grain_len].copy()\n",
    "    grains = x_cut.reshape(num_grains, grain_len)\n",
    "\n",
    "    order = np.random.permutation(num_grains)\n",
    "    grains_shuffled = grains[order, :]\n",
    "\n",
    "    y = grains_shuffled.reshape(-1)\n",
    "    return y\n",
    "\n",
    "\n",
    "# generate variations\n",
    "variations = {}\n",
    "\n",
    "# === NUEVAS FUNCIONES: time-stretch + delay + reverb ===\n",
    "\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "def time_stretch_phase_vocoder(x, fs, stretch=1.3, N_fft=2048, hop=512):\n",
    "    \"\"\"\n",
    "    Time-stretch sencillo estilo phase vocoder.\n",
    "    stretch > 1 alarga el audio manteniendo aproximadamente el pitch.\n",
    "    \"\"\"\n",
    "    # STFT\n",
    "    f, t, Z = stft(\n",
    "        x,\n",
    "        fs=fs,\n",
    "        window=\"hann\",\n",
    "        nperseg=N_fft,\n",
    "        noverlap=N_fft - hop,\n",
    "        padded=False,\n",
    "        boundary=None\n",
    "    )\n",
    "\n",
    "    mag = np.abs(Z)\n",
    "    phase = np.angle(Z)\n",
    "\n",
    "    num_bins, num_frames = Z.shape\n",
    "    new_num_frames = int(np.ceil(num_frames * stretch))\n",
    "\n",
    "    Y = np.zeros((num_bins, new_num_frames), dtype=np.complex64)\n",
    "\n",
    "    # avance de fase teórico\n",
    "    omega = 2.0 * np.pi * hop * np.arange(num_bins) / float(N_fft)\n",
    "\n",
    "    # inicializamos acumulador de fase con el primer frame\n",
    "    phase_acc = phase[:, 0].copy()\n",
    "    Y[:, 0] = mag[:, 0] * np.exp(1j * phase_acc)\n",
    "\n",
    "    # recorremos los frames nuevos\n",
    "    for n in range(1, new_num_frames):\n",
    "        t_orig = n / stretch\n",
    "        k = int(np.floor(t_orig))\n",
    "        if k >= num_frames - 1:\n",
    "            break\n",
    "\n",
    "        frac = t_orig - k\n",
    "\n",
    "        # interpolación lineal de magnitud\n",
    "        mag_t = (1.0 - frac) * mag[:, k] + frac * mag[:, k + 1]\n",
    "\n",
    "        # actualización de fase (phase locking simple)\n",
    "        delta = phase[:, k + 1] - phase[:, k] - omega\n",
    "        # llevar delta al rango [-pi, pi]\n",
    "        delta = (delta + np.pi) % (2.0 * np.pi) - np.pi\n",
    "\n",
    "        phase_acc += omega + delta\n",
    "        Y[:, n] = mag_t * np.exp(1j * phase_acc)\n",
    "\n",
    "    # iSTFT\n",
    "    _, y = istft(\n",
    "        Y,\n",
    "        fs=fs,\n",
    "        window=\"hann\",\n",
    "        nperseg=N_fft,\n",
    "        noverlap=N_fft - hop,\n",
    "        input_onesided=True\n",
    "    )\n",
    "\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "\n",
    "def apply_simple_delay(x, fs, delay_time=0.28, feedback=0.45, mix=0.35, num_taps=4):\n",
    "    \"\"\"\n",
    "    Delay sencillo multitap en el dominio del tiempo.\n",
    "    - delay_time: segundos entre repeticiones\n",
    "    - feedback: cuánto decae cada tap\n",
    "    - mix: mezcla wet/dry\n",
    "    \"\"\"\n",
    "    x = x.astype(np.float32)\n",
    "    y = x.copy()\n",
    "\n",
    "    delay_samples = int(delay_time * fs)\n",
    "\n",
    "    for k in range(1, num_taps + 1):\n",
    "        d = delay_samples * k\n",
    "        if d >= len(x):\n",
    "            break\n",
    "        y[d:] += (feedback ** k) * x[:-d]\n",
    "\n",
    "    peak = np.max(np.abs(y)) + 1e-9\n",
    "    y = y / peak\n",
    "\n",
    "    return (1.0 - mix) * x + mix * y\n",
    "\n",
    "\n",
    "def apply_simple_reverb(x, fs, reverb_time=1.2, mix=0.4):\n",
    "    \"\"\"\n",
    "    Reverb muy simple por convolución con una IR sintética.\n",
    "    - reverb_time: tiempo de decaimiento aprox (segundos)\n",
    "    - mix: mezcla wet/dry\n",
    "    \"\"\"\n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "    ir_len = int(reverb_time * fs)\n",
    "    t_ir = np.arange(ir_len) / fs\n",
    "\n",
    "    # IR: decaimiento exponencial + pizca de ruido para textura\n",
    "    ir = np.exp(-3.0 * t_ir / reverb_time).astype(np.float32)\n",
    "    ir *= (0.9 + 0.1 * np.random.randn(ir_len)).astype(np.float32)\n",
    "\n",
    "    y = fftconvolve(x, ir, mode=\"full\")[:len(x)]\n",
    "\n",
    "    peak = np.max(np.abs(y)) + 1e-9\n",
    "    y = y / peak\n",
    "\n",
    "    return (1.0 - mix) * x + mix * y\n",
    "\n",
    "# pitch up +5 semitonos\n",
    "y_pitch_up, fs_pitch_up = transform_pitch_resample(x, fs, semitones=5)\n",
    "\n",
    "# resample back to fs original para compararlo y usarlo luego en la mezcla\n",
    "y_pitch_up = resample_poly(y_pitch_up, up=fs, down=fs_pitch_up)\n",
    "variations[\"pitch_up_+5st\"] = y_pitch_up\n",
    "\n",
    "# low-pass (here 2000 hz)\n",
    "y_lowpass = transform_lowpass_fft(x, fs, cutoff_hz=2000)\n",
    "variations[\"lowpass_2kHz\"] = y_lowpass\n",
    "\n",
    "# brighten (tilt)\n",
    "y_bright = transform_brighten_spectral_tilt(x, fs, tilt_db_per_khz=6.0)\n",
    "variations[\"bright_tilt\"] = y_bright\n",
    "\n",
    "# spectral freeze\n",
    "y_freeze = transform_spectral_freeze(x, fs, freeze_time=0.5)\n",
    "variations[\"spectral_freeze\"] = y_freeze\n",
    "\n",
    "# granular shuffle\n",
    "np.random.seed(0)  \n",
    "y_granular = transform_granular_shuffle(x, fs, grain_ms=80)  \n",
    "variations[\"granular_shuffle\"] = y_granular\n",
    "\n",
    "# save and play\n",
    "for name, y in variations.items():\n",
    "    if y is None or len(y) == 0:\n",
    "        print(f\"{name}: variación vacía, se omite.\")\n",
    "        continue\n",
    "\n",
    "    # normalization\n",
    "    peak = np.max(np.abs(y)) + 1e-9\n",
    "    y_norm = y / peak * 0.9\n",
    "    out_path = os.path.join(BASE_DIR, f\"universildo_{SOUND_ID}_{name}.wav\")\n",
    "    sf.write(out_path, (y_norm * 32767).astype(np.int16), fs)\n",
    "    print(name, \"->\", out_path, \"dur(s):\", len(y_norm)/fs)\n",
    "\n",
    "# play current result (OJO: change name if saving mulitple)\n",
    "ipd.Audio(variations[\"granular_shuffle\"], rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae380e3b",
   "metadata": {},
   "source": [
    "### HARMONIZATION TOOLS\n",
    "\n",
    "We will use these to define the triads (major and minor) and the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d30322",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.3 utilidades para armonizar (triadas + bajos + acordes de fondo)\n",
    "\n",
    "# estimar f0 de un segmento usando el pico espectral más fuerte\n",
    "def estimate_f0_segment(x_seg, fs, fmin=150.0, fmax=2000.0):\n",
    "    if len(x_seg) == 0:\n",
    "        return None\n",
    "    w = np.hanning(len(x_seg))\n",
    "    xw = x_seg * w\n",
    "\n",
    "    # next pow 2\n",
    "    N = 1\n",
    "    while N < len(xw):\n",
    "        N *= 2\n",
    "\n",
    "    X = np.fft.rfft(xw, n=N)\n",
    "    freqs = np.fft.rfftfreq(N, d=1/fs)\n",
    "\n",
    "    band = (freqs >= fmin) & (freqs <= fmax)\n",
    "    if not np.any(band):\n",
    "        return None\n",
    "\n",
    "    mag = np.abs(X[band])\n",
    "    if mag.size == 0:\n",
    "        return None\n",
    "\n",
    "    idx = np.argmax(mag)\n",
    "    f0 = freqs[band][idx]\n",
    "    return f0\n",
    "\n",
    "# utils midi <-> hz\n",
    "def hz_to_midi(f):\n",
    "    return 69 + 12 * np.log2(f / 440.0)\n",
    "\n",
    "def midi_to_hz(m):\n",
    "    return 440.0 * (2.0 ** ((m - 69) / 12.0))\n",
    "\n",
    "# decidir intervalos de triada asumiendo modo menor relativo al grado i\n",
    "def triad_intervals_for_midi(midi_root):\n",
    "    # relativo al la (57) solo para decidir calidad del acorde\n",
    "    rel = (midi_root - 57) % 12\n",
    "\n",
    "    # grados de la menor natural (solo para escoger tipo de triada por grado)\n",
    "    degree_quality = {\n",
    "        0: \"min\",   # i\n",
    "        2: \"dim\",   # ii°\n",
    "        3: \"maj\",   # III\n",
    "        5: \"min\",   # iv\n",
    "        7: \"min\",   # v\n",
    "        8: \"maj\",   # VI\n",
    "        10: \"maj\"   # VII\n",
    "    }\n",
    "\n",
    "    q = degree_quality.get(rel, \"min\")\n",
    "    if q == \"maj\":\n",
    "        return [0, 4, 7]\n",
    "    elif q == \"dim\":\n",
    "        return [0, 3, 6]\n",
    "    else:\n",
    "        return [0, 3, 7]\n",
    "\n",
    "# construir una triada a partir de un segmento (usamos st + resample)\n",
    "def make_triad_from_segment(x_seg, fs, base_f0=None):\n",
    "    if len(x_seg) == 0:\n",
    "        return x_seg\n",
    "\n",
    "    if base_f0 is None:\n",
    "        base_f0 = estimate_f0_segment(x_seg, fs)\n",
    "\n",
    "    if base_f0 is None or base_f0 <= 0:\n",
    "        return x_seg.copy()\n",
    "\n",
    "    midi_root = hz_to_midi(base_f0)\n",
    "    intervals = triad_intervals_for_midi(midi_root)\n",
    "\n",
    "    voices = []\n",
    "    for st in intervals:\n",
    "        if st == 0:\n",
    "            voices.append(x_seg.copy())\n",
    "        else:\n",
    "            y, fs_y = transform_pitch_resample(x_seg, fs, semitones=st)\n",
    "            y = resample_poly(y, up=fs, down=fs_y)\n",
    "            voices.append(y)\n",
    "\n",
    "    min_len = min(len(v) for v in voices)\n",
    "    voices = [v[:min_len] for v in voices]\n",
    "\n",
    "    chord = np.sum(voices, axis=0)\n",
    "    peak = np.max(np.abs(chord)) + 1e-9\n",
    "    chord = chord / peak * 0.9\n",
    "    return chord.astype(np.float32)\n",
    "\n",
    "# generar una capa de bajo (parámetros flexibles)\n",
    "def make_bassline_layer(f0_root, fs, duration_sec, bpm=120,\n",
    "                        octaves_down=1, note_division=\"quarters\", amp=0.4):\n",
    "    \"\"\"\n",
    "    f0_root: frecuencia base (grado i)\n",
    "    octaves_down: cuántas octavas abajo\n",
    "    note_division: \"quarters\" (negras) o \"eighths\" (corcheas)\n",
    "    amp: ganancia relativa de esta capa\n",
    "    \"\"\"\n",
    "    if f0_root is None or f0_root <= 0:\n",
    "        return np.zeros(int(duration_sec * fs), dtype=np.float32)\n",
    "\n",
    "    f = f0_root / (2.0 ** octaves_down)\n",
    "    t = np.arange(int(duration_sec * fs)) / fs\n",
    "    bass = np.sin(2 * np.pi * f * t)\n",
    "\n",
    "    if note_division == \"quarters\":\n",
    "        beat_dur = 60.0 / bpm\n",
    "    else:  # \"eighths\"\n",
    "        beat_dur = 60.0 / bpm / 2.0\n",
    "\n",
    "    env = np.zeros_like(bass)\n",
    "    num_beats = int(duration_sec / beat_dur) + 1\n",
    "\n",
    "    for b in range(num_beats):\n",
    "        start = int(b * beat_dur * fs)\n",
    "        end = min(len(env), start + int(beat_dur * fs * 0.8))\n",
    "        if start >= len(env):\n",
    "            break\n",
    "        seg_len = end - start\n",
    "        if seg_len <= 0:\n",
    "            continue\n",
    "\n",
    "        fade_len = min(int(0.05 * fs), seg_len)\n",
    "        e = np.ones(seg_len)\n",
    "        if fade_len > 0:\n",
    "            e[:fade_len] *= np.linspace(0.0, 1.0, fade_len)\n",
    "            e[-fade_len:] *= np.linspace(1.0, 0.0, fade_len)\n",
    "        env[start:end] = np.maximum(env[start:end], e)\n",
    "\n",
    "    bass *= env\n",
    "    peak = np.max(np.abs(bass)) + 1e-9\n",
    "    bass = bass / peak * amp\n",
    "    return bass.astype(np.float32)\n",
    "\n",
    "# generar un acorde a partir de f0_root y lista de intervalos (en semitonos)\n",
    "def make_chord_from_f0(f0_root, fs, duration_sec, intervals, amp=0.3):\n",
    "    \"\"\"\n",
    "    Genera un acorde sinusoidal a partir de una frecuencia raíz y una lista de\n",
    "    intervalos en semitonos, limitando TODAS las voces al rango [150, 440] Hz.\n",
    "    \"\"\"\n",
    "    if f0_root is None or f0_root <= 0:\n",
    "        return np.zeros(int(duration_sec * fs), dtype=np.float32)\n",
    "\n",
    "    t = np.arange(int(duration_sec * fs)) / fs\n",
    "    sig = np.zeros_like(t, dtype=np.float32)\n",
    "\n",
    "    min_f = 150.0\n",
    "    max_f = 440.0\n",
    "\n",
    "    for st in intervals:\n",
    "        # frecuencia teórica\n",
    "        f = f0_root * (2.0 ** (st / 12.0))\n",
    "\n",
    "        # plegamos por octavas hasta que quede en [min_f, max_f]\n",
    "        while f > max_f:\n",
    "            f /= 2.0\n",
    "        while f < min_f:\n",
    "            f *= 2.0\n",
    "\n",
    "        # sumamos esta voz\n",
    "        sig += np.sin(2.0 * np.pi * f * t).astype(np.float32)\n",
    "\n",
    "    peak = np.max(np.abs(sig)) + 1e-9\n",
    "    sig = sig / peak * amp\n",
    "    return sig.astype(np.float32)\n",
    "\n",
    "# acordes de fondo: loop entre i menor y iv mayor con séptima \"disminuida\" (b7)\n",
    "def make_background_chords(f0_root, fs, duration_sec, bpm=120):\n",
    "    \"\"\"\n",
    "    i: triada menor sobre f0_root\n",
    "    iv: triada mayor + 7ª disminuida (b7) sobre grado iv (f0_root + 5 semitonos)\n",
    "    \"\"\"\n",
    "    if f0_root is None or f0_root <= 0:\n",
    "        return np.zeros(int(duration_sec * fs), dtype=np.float32)\n",
    "\n",
    "    bar_sec = 4 * 60.0 / bpm   # un compás de 4/4\n",
    "    chords = []\n",
    "    t_acc = 0.0\n",
    "    toggle = 0\n",
    "\n",
    "    while t_acc < duration_sec + 1e-3:\n",
    "        if toggle % 2 == 0:\n",
    "            # grado i: triada menor\n",
    "            f_root = f0_root\n",
    "            intervals = [0, 3, 7]\n",
    "        else:\n",
    "            # grado iv: triada mayor + b7 (0, 4, 7, 10)\n",
    "            f_root = f0_root * (2.0 ** (5.0 / 12.0))\n",
    "            intervals = [0, 4, 7, 10]\n",
    "\n",
    "        chord = make_chord_from_f0(f_root, fs, bar_sec, intervals, amp=0.25)\n",
    "        chords.append(chord)\n",
    "\n",
    "        t_acc += bar_sec\n",
    "        toggle += 1\n",
    "\n",
    "    pad = np.concatenate(chords)\n",
    "    total_samples = int(duration_sec * fs)\n",
    "\n",
    "    if len(pad) > total_samples:\n",
    "        pad = pad[:total_samples]\n",
    "    else:\n",
    "        pad = np.pad(pad, (0, total_samples - len(pad)))\n",
    "\n",
    "    return pad.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501695f2",
   "metadata": {},
   "source": [
    "### SEGEMENT NOTEES, CREATE TRIADS AND MIX\n",
    "\n",
    "\n",
    "We will build the main them with an intro, chords and bassline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f999a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Objetivo:\n",
    "# - 4 s iniciales: SOLO la flauta original (segmento recortado)\n",
    "# - Luego:\n",
    "#   * Primera vez que suena la melodía completa\n",
    "#   * Última nota levemente prolongada\n",
    "#   * Pausa de 0.5 s\n",
    "# - Después de eso:\n",
    "#   * Progresión de acordes con más peso (~16 s fijos)\n",
    "#   * Melodía extendida (notas 4× su duración) con delay + reverb\n",
    "#   * 3 capas de bajo (2, 3 y 4 octavas abajo)\n",
    "#\n",
    "# Usamos x como audio recortado (x_edit re-leído) y fs\n",
    "\n",
    "# 1) Segmentamos las primeras notas para estimar f0_root\n",
    "note_times = [0.0, 0.9, 1.7, 2.5, 3.3, 4.2]  # aprox 5 notas dentro del recorte\n",
    "note_segments = []\n",
    "\n",
    "for i in range(len(note_times) - 1):\n",
    "    s0 = int(note_times[i] * fs)\n",
    "    s1 = int(note_times[i+1] * fs)\n",
    "    seg = x[s0:s1]\n",
    "    note_segments.append(seg)\n",
    "\n",
    "print(\"número de segmentos de nota:\", len(note_segments))\n",
    "\n",
    "# estimamos f0_root como la primera f0 válida\n",
    "f0_root = None\n",
    "for seg in note_segments:\n",
    "    f0_seg = estimate_f0_segment(seg, fs)\n",
    "    if f0_seg is not None and f0_seg > 0:\n",
    "        f0_root = f0_seg\n",
    "        break\n",
    "\n",
    "print(\"f0_root estimada:\", f0_root)\n",
    "\n",
    "if f0_root is None or f0_root <= 0:\n",
    "    f0_root = 440.0  # fallback por si acaso\n",
    "\n",
    "# 2) Intro base: 4 segundos SOLO flauta original (sin acordes, sin bajo)\n",
    "intro_dur_sec = 4.0\n",
    "intro_samples = int(intro_dur_sec * fs)\n",
    "\n",
    "# si el recorte es más corto que 4s, lo repetimos\n",
    "def tile_to_len(sig, L):\n",
    "    if len(sig) == 0:\n",
    "        return np.zeros(L, dtype=np.float32)\n",
    "    reps = int(np.ceil(L / len(sig)))\n",
    "    out = np.tile(sig, reps)[:L]\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "if len(x) >= intro_samples:\n",
    "    intro = x[:intro_samples]\n",
    "else:\n",
    "    intro = tile_to_len(x, intro_samples)\n",
    "\n",
    "intro = intro.astype(np.float32)\n",
    "\n",
    "# 2b) Prolongar levemente la última nota y añadir una pausa de 0.5 s\n",
    "if len(note_segments) > 0:\n",
    "    last_note_seg = note_segments[-1].astype(np.float32)\n",
    "    # pequeño time-stretch de la última nota\n",
    "    y_last = time_stretch_phase_vocoder(last_note_seg, fs, stretch=1.5)\n",
    "    y_last = y_last.astype(np.float32)\n",
    "\n",
    "    # para evitar repetir el ataque, usamos solo la \"cola\" extra\n",
    "    if len(y_last) > len(last_note_seg):\n",
    "        y_tail = y_last[len(last_note_seg):]\n",
    "    else:\n",
    "        y_tail = y_last\n",
    "\n",
    "    gap = np.zeros(int(0.5 * fs), dtype=np.float32)  # pausa de medio segundo\n",
    "    intro_global = np.concatenate([intro, y_tail, gap]).astype(np.float32)\n",
    "else:\n",
    "    intro_global = intro.astype(np.float32)\n",
    "\n",
    "print(\"duración intro_global (s):\", len(intro_global) / fs)\n",
    "\n",
    "# 3) Construimos la progresión de acordes base (forzamos ~16 s)\n",
    "\n",
    "bpm = 120\n",
    "bar_sec = 4 * 60.0 / bpm   # 4/4 -> 2 s por compás\n",
    "n_cycles = 2               # 4 compases * 2 ciclos = 8 compases ~ 16 s\n",
    "\n",
    "progression_bars = []\n",
    "\n",
    "# frecuencias raíz PARA CADA GRADO, UNA OCTAVA MÁS GRAVE\n",
    "f_i   = f0_root / 2.0                                # i una octava abajo\n",
    "f_iv  = f0_root * (2.0 ** (5.0 / 12.0)) / 2.0        # iv - 1 octava\n",
    "f_iii = f0_root * (2.0 ** (3.0 / 12.0)) / 2.0        # III - 1 octava\n",
    "\n",
    "# intervalos de los acordes:\n",
    "intervals_i      = [0, 3, 7]          # i: triada menor\n",
    "intervals_iv7b   = [0, 4, 7, 10]      # iv7(b7): triada mayor + 7ª menor\n",
    "intervals_iii7   = [0, 4, 7, 11]      # IIImaj7 (séptima mayor)\n",
    "\n",
    "for _ in range(n_cycles):\n",
    "    # i menor\n",
    "    progression_bars.append(\n",
    "        make_chord_from_f0(f_i, fs, bar_sec, intervals_i, amp=0.5)\n",
    "    )\n",
    "    # iv7(b7)\n",
    "    progression_bars.append(\n",
    "        make_chord_from_f0(f_iv, fs, bar_sec, intervals_iv7b, amp=0.5)\n",
    "    )\n",
    "    # III7 (aquí maj7)\n",
    "    progression_bars.append(\n",
    "        make_chord_from_f0(f_iii, fs, bar_sec, intervals_iii7, amp=0.5)\n",
    "    )\n",
    "    # iv7(b7) otra vez\n",
    "    progression_bars.append(\n",
    "        make_chord_from_f0(f_iv, fs, bar_sec, intervals_iv7b, amp=0.5)\n",
    "    )\n",
    "\n",
    "chords_prog = np.concatenate(progression_bars).astype(np.float32)\n",
    "\n",
    "# aseguramos que la sección armónica es EXACTAMENTE 16 s\n",
    "chord_section_sec = 16.0\n",
    "harm_section_len = int(chord_section_sec * fs)\n",
    "\n",
    "if len(chords_prog) > harm_section_len:\n",
    "    chords_prog = chords_prog[:harm_section_len]\n",
    "else:\n",
    "    chords_prog = np.pad(chords_prog, (0, harm_section_len - len(chords_prog)))\n",
    "\n",
    "print(\"duración sección acordes base (s):\", len(chords_prog) / fs)\n",
    "\n",
    "# pequeño fade-in para que los acordes no entren de golpe\n",
    "fade_in_sec = 2.0\n",
    "fade_samples = min(int(fade_in_sec * fs), len(chords_prog))\n",
    "\n",
    "env = np.ones_like(chords_prog, dtype=np.float32)\n",
    "env[:fade_samples] = np.linspace(0.0, 1.0, fade_samples).astype(np.float32)\n",
    "chords_prog = chords_prog * env\n",
    "\n",
    "# 4) Melodía extendida después de la intro_global:\n",
    "#    cada nota 4× su duración, con delay + reverb\n",
    "\n",
    "note_stretch_factor = 4.0  # nota original + 3× su tiempo adicional\n",
    "\n",
    "extended_segments = []\n",
    "for seg in note_segments:\n",
    "    if len(seg) == 0:\n",
    "        continue\n",
    "    y_ext = time_stretch_phase_vocoder(seg.astype(np.float32), fs, stretch=note_stretch_factor)\n",
    "    extended_segments.append(y_ext.astype(np.float32))\n",
    "\n",
    "if len(extended_segments) > 0:\n",
    "    extended_melody = np.concatenate(extended_segments).astype(np.float32)\n",
    "else:\n",
    "    # fallback silencioso si algo sale mal\n",
    "    extended_melody = np.zeros(harm_section_len, dtype=np.float32)\n",
    "\n",
    "# Ajustamos la longitud de la melodía extendida a la sección armónica (16 s)\n",
    "if len(extended_melody) < harm_section_len:\n",
    "    extended_melody = np.pad(extended_melody, (0, harm_section_len - len(extended_melody)))\n",
    "else:\n",
    "    extended_melody = extended_melody[:harm_section_len]\n",
    "\n",
    "# Delay para darle movimiento rítmico\n",
    "melody_body = apply_simple_delay(\n",
    "    extended_melody,\n",
    "    fs,\n",
    "    delay_time=0.28,   # ~corchea con swing a 120 bpm\n",
    "    feedback=0.45,\n",
    "    mix=0.35\n",
    ")\n",
    "\n",
    "# Reverb sencilla para dar espacio\n",
    "melody_body = apply_simple_reverb(\n",
    "    melody_body,\n",
    "    fs,\n",
    "    reverb_time=1.2,\n",
    "    mix=0.4\n",
    ")\n",
    "\n",
    "# Pista completa: intro_global (con última nota prolongada + pausa)\n",
    "# + cuerpo extendido (16 s)\n",
    "melody_track = np.concatenate([intro_global, melody_body]).astype(np.float32)\n",
    "\n",
    "# 5) Cama armónica: silencio durante toda la intro_global + acordes después\n",
    "harm_intro_silence = np.zeros(len(intro_global), dtype=np.float32)\n",
    "theme_harm = np.concatenate([harm_intro_silence, chords_prog]).astype(np.float32)\n",
    "\n",
    "# 6) Duración total del tema\n",
    "assert len(melody_track) == len(theme_harm)\n",
    "total_sec = len(melody_track) / fs\n",
    "print(\"duración total tema (s):\", total_sec)\n",
    "\n",
    "# 7) Tres capas de bajo (entrando después de la intro_global + ~1 s)\n",
    "\n",
    "bass_quarters = make_bassline_layer(\n",
    "    f0_root, fs, total_sec,\n",
    "    bpm=120,\n",
    "    octaves_down=2,      # 2 octavas abajo\n",
    "    note_division=\"quarters\",\n",
    "    amp=0.32\n",
    ")\n",
    "\n",
    "bass_eighths = make_bassline_layer(\n",
    "    f0_root, fs, total_sec,\n",
    "    bpm=120,\n",
    "    octaves_down=3,      # 3 octavas abajo\n",
    "    note_division=\"eighths\",\n",
    "    amp=0.5\n",
    ")\n",
    "\n",
    "bass_eighths_5 = make_bassline_layer(\n",
    "    f0_root, fs, total_sec,\n",
    "    bpm=120,\n",
    "    octaves_down=5,      # 5 octavas abajo\n",
    "    note_division=\"quarters\",\n",
    "    amp=0.5\n",
    ")\n",
    "\n",
    "bass_sub = make_bassline_layer(\n",
    "    f0_root, fs, total_sec,\n",
    "    bpm=120,\n",
    "    octaves_down=4,      # nueva capa aún más grave\n",
    "    note_division=\"quarters\",\n",
    "    amp=0.28\n",
    ")\n",
    "\n",
    "# calculamos cuándo empiezan los acordes (fin de la intro_global)\n",
    "chord_start_sec = len(intro_global) / fs\n",
    "bass_start_sec = chord_start_sec + 1.0    # bajo entra ~1 s después de los acordes\n",
    "bass_start_samples = int(bass_start_sec * fs)\n",
    "\n",
    "bass_quarters[:bass_start_samples] = 0.0\n",
    "bass_eighths[:bass_start_samples] = 0.0\n",
    "bass_eighths_5[:bass_start_samples] = 0.0\n",
    "bass_sub[:bass_start_samples]     = 0.0\n",
    "\n",
    "# 8) Igualamos longitudes (por seguridad)\n",
    "L = len(melody_track)\n",
    "\n",
    "def fix_len(y, L):\n",
    "    if len(y) < L:\n",
    "        return np.pad(y, (0, L - len(y)))\n",
    "    else:\n",
    "        return y[:L]\n",
    "\n",
    "theme_harm    = fix_len(theme_harm, L)\n",
    "bass_quarters = fix_len(bass_quarters, L)\n",
    "bass_eighths  = fix_len(bass_eighths, L)\n",
    "bass_eighths_5  = fix_len(bass_eighths_5, L)\n",
    "bass_sub      = fix_len(bass_sub, L)\n",
    "\n",
    "# 9) Mezcla final: flauta + acordes + 3 capas de bajo\n",
    "mix_theme = melody_track + theme_harm + bass_quarters + bass_eighths + bass_sub + bass_eighths_5\n",
    "\n",
    "print(\"len melody_track (s):\", len(melody_track)/fs)\n",
    "print(\"len theme_harm (s):\", len(theme_harm)/fs)\n",
    "\n",
    "# 10) Limitar a 30 s por si acaso\n",
    "max_total_sec = 30.0\n",
    "max_samples = int(max_total_sec * fs)\n",
    "if len(mix_theme) > max_samples:\n",
    "    mix_theme = mix_theme[:max_samples]\n",
    "\n",
    "# 11) Normalización\n",
    "peak = np.max(np.abs(mix_theme)) + 1e-9\n",
    "mix_theme = mix_theme / peak * 0.95\n",
    "\n",
    "final_path = os.path.join(BASE_DIR, f\"universildo_{SOUND_ID}_final_harmonized.wav\")\n",
    "sf.write(final_path, (mix_theme * 32767).astype(np.int16), fs)\n",
    "print(\"final harmonized mix saved in:\", final_path)\n",
    "print(\"length in s:\", len(mix_theme)/fs)\n",
    "\n",
    "# =====================================================\n",
    "# CODA FINAL: acorde base con ataque + delay + reverb\n",
    "# =====================================================\n",
    "\n",
    "# 1) Atenuar un poco el final del tema actual\n",
    "fade_tail_sec = 0.5          # últimos 0.5 s\n",
    "fade_tail_samples = min(int(fade_tail_sec * fs), len(mix_theme))\n",
    "\n",
    "env_tail = np.ones_like(mix_theme, dtype=np.float32)\n",
    "env_tail[-fade_tail_samples:] = np.linspace(1.0, 0.4, fade_tail_samples).astype(np.float32)\n",
    "mix_theme_faded = mix_theme * env_tail\n",
    "\n",
    "# 2) Construir el último acorde (i menor, acorde base) de ~4 s\n",
    "final_chord_dur_sec = 4.0    # máx 4 s\n",
    "intervals_final = intervals_i   # usamos la triada i menor que ya definiste\n",
    "f_final_root = f_i              # misma raíz grave que en la progresión\n",
    "\n",
    "final_chord = make_chord_from_f0(\n",
    "    f_final_root,\n",
    "    fs,\n",
    "    final_chord_dur_sec,\n",
    "    intervals_final,\n",
    "    amp=0.8    # un poquito más presente\n",
    ")\n",
    "\n",
    "# 3) Envolvente: ataque corto + caída larga\n",
    "N_final = len(final_chord)\n",
    "attack_sec = 0.15\n",
    "attack_samples = min(int(attack_sec * fs), N_final)\n",
    "\n",
    "attack_env = np.linspace(0.0, 1.0, attack_samples, dtype=np.float32)\n",
    "sustain_env = np.ones(N_final - attack_samples, dtype=np.float32)\n",
    "env_final = np.concatenate([attack_env, sustain_env])\n",
    "\n",
    "# caída global hacia el silencio\n",
    "decay_env = np.linspace(1.0, 0.0, N_final, dtype=np.float32)\n",
    "env_final *= decay_env\n",
    "\n",
    "final_chord *= env_final.astype(np.float32)\n",
    "\n",
    "# 4) Delay y reverb para que se quede flotando bonito\n",
    "final_chord = apply_simple_delay(\n",
    "    final_chord,\n",
    "    fs,\n",
    "    delay_time=0.32,   # algo cercano a corchea a 120 bpm\n",
    "    feedback=0.45,\n",
    "    mix=0.45,\n",
    "    num_taps=5\n",
    ")\n",
    "\n",
    "final_chord = apply_simple_reverb(\n",
    "    final_chord,\n",
    "    fs,\n",
    "    reverb_time=2.0,   # un poco más larga que el cuerpo\n",
    "    mix=0.6\n",
    ")\n",
    "\n",
    "# 5) Concatenar tema + coda\n",
    "full_mix = np.concatenate([mix_theme_faded, final_chord]).astype(np.float32)\n",
    "\n",
    "# 6) Normalización global\n",
    "peak_full = np.max(np.abs(full_mix)) + 1e-9\n",
    "full_mix = full_mix / peak_full * 0.95\n",
    "\n",
    "final_coda_path = os.path.join(BASE_DIR, f\"universildo_{SOUND_ID}_final_harmonized_coda.wav\")\n",
    "sf.write(final_coda_path, (full_mix * 32767).astype(np.int16), fs)\n",
    "\n",
    "print(\"final mix WITH CODA saved in:\", final_coda_path)\n",
    "print(\"length in s (with coda):\", len(full_mix) / fs)\n",
    "\n",
    "ipd.Audio(full_mix, rate=fs)\n",
    "\n",
    "ipd.Audio(mix_theme, rate=fs)\n",
    "print(\"max intro_global:\", np.max(np.abs(intro_global)))\n",
    "ipd.Audio(intro_global, rate=fs)\n",
    "\n",
    "y_check, fs_check = sf.read(final_coda_path)\n",
    "print(\"fs_check:\", fs_check)\n",
    "print(\"duración archivo leido (s):\", len(y_check) / fs_check)\n",
    "\n",
    "ipd.Audio(y_check, rate=fs_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max intro:\", np.max(np.abs(intro)))\n",
    "ipd.Audio(intro, rate=fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsp-virtual-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
